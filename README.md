# ğŸ¤– Jarvis â€” Always-On Ambient AI Copilot

[![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![Gemini API](https://img.shields.io/badge/Google-Gemini%20API-4285F4?logo=google&logoColor=white)](https://ai.google.dev/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**An always-on, screen-aware AI copilot that sees your screen, hears your audio, stays silent until called, and delegates complex tasks to a background agent â€” powered by Gemini 2.5 Flash (real-time perception) and Gemini 3 Flash (deep reasoning).**

*Built for the Gemini 3 Hackathon (Google DeepMind Ã— Devpost)*

</div>

---

## How It Works

Jarvis runs three independent layers that work together:

| Mode | What Happens | API Cost |
|------|-------------|----------|
| **Passive** | Audio â†’ Whisper â†’ transcript buffer. Screen â†’ JPEG â†’ frame buffer. Zero API calls. | $0 |
| **Active** | Wake word â†’ open Live API session â†’ inject context â†’ stream live audio + screen â†’ voice responses | Free tier |
| **Task Delegation** | User asks complex task â†’ Live API function call â†’ Gemini 3 Flash runs autonomously â†’ result announced via voice | Free tier |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: LOCAL  (Always Running Â· Zero API Cost)            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ System Audio   â”‚  â”‚ Screen Capture â”‚  â”‚  Wake Word    â”‚  â”‚
â”‚  â”‚ â†’ faster-      â”‚  â”‚ â†’ mss + Pillow â”‚  â”‚  Detection    â”‚  â”‚
â”‚  â”‚   whisper      â”‚  â”‚ â†’ 1fps JPEG    â”‚  â”‚  ("Jarvis")   â”‚  â”‚
â”‚  â”‚   (local)      â”‚  â”‚   frames       â”‚  â”‚  string match â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚                   â”‚                   â”‚           â”‚
â”‚          â–¼                   â–¼                   â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚           â”‚
â”‚  â”‚     Rolling Context Buffer      â”‚            â”‚           â”‚
â”‚  â”‚  (last 5 min transcript +       â”‚            â”‚           â”‚
â”‚  â”‚   last 10 screen frames)        â”‚            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚           â”‚
â”‚                                                  â”‚           â”‚
â”‚  No API calls. No tokens burned. Local compute.  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                               Wake word detected! â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: GEMINI 2.5 FLASH LIVE API  (On-Demand Session)     â”‚
â”‚                                                              â”‚
â”‚  â€¢ Opened ONLY when wake word fires                          â”‚
â”‚  â€¢ Receives: context buffer + live audio + live screen       â”‚
â”‚  â€¢ Provides: real-time voice conversation                    â”‚
â”‚  â€¢ Streams screen at 1fps for visual understanding           â”‚
â”‚  â€¢ Closes after 30s silence â†’ back to passive                â”‚
â”‚                                                              â”‚
â”‚  Function call: start_background_task(description)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Function call triggered
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: GEMINI 3 FLASH  (Background Task Execution)        â”‚
â”‚                                                              â”‚
â”‚  â€¢ Receives task description + relevant context              â”‚
â”‚  â€¢ Runs autonomously with code_execution tool                â”‚
â”‚  â€¢ Result injected back into Layer 2 session                 â”‚
â”‚  â€¢ Layer 2 announces result to user via voice                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Language | Python 3.11+ |
| Package manager | [uv](https://github.com/astral-sh/uv) |
| Gemini SDK | `google-genai` |
| Local transcription | `faster-whisper` (runs on CPU, no API cost) |
| Screen capture | `mss` + `Pillow` |
| Audio capture | `sounddevice` |
| Audio playback | `pyaudio` |
| Audio processing | `numpy` |
| Observability | `langfuse` (optional) |

### Models Used

| Purpose | Model |
|---------|-------|
| Real-time perception (Live API) | `gemini-2.5-flash-native-audio-preview-12-2025` |
| Background task execution | `gemini-3-flash-preview` |

---

## Setup

### Prerequisites

- Python 3.11+
- [uv](https://github.com/astral-sh/uv) package manager
- macOS: [BlackHole](https://existential.audio/blackhole/) for system audio capture

### Installation

```bash
# Clone
git clone https://github.com/user/jarvis.git
cd jarvis

# Install with uv
uv sync

# macOS: Install BlackHole for system audio capture
# Download from https://existential.audio/blackhole/

# Set API key
export GEMINI_API_KEY="your-key-here"

# Run
uv run jarvis

# Options
uv run jarvis --list-devices  # Show audio devices
uv run jarvis --device 1      # Use specific audio device
uv run jarvis --debug          # Enable verbose logging
```

---

## File Structure

```
jarvis/
â”œâ”€â”€ main.py                 # Entry point, orchestrates all layers
â”œâ”€â”€ config.py               # Settings, model names, buffer sizes
â”œâ”€â”€ layer1/
â”‚   â”œâ”€â”€ audio_capture.py    # System audio + local Whisper transcription
â”‚   â”œâ”€â”€ screen_capture.py   # Screen capture + frame buffer
â”‚   â””â”€â”€ wake_word.py        # Wake word detection
â”œâ”€â”€ layer2/
â”‚   â”œâ”€â”€ live_session.py     # Gemini Live API session management
â”‚   â”œâ”€â”€ context_inject.py   # Buffer â†’ Live API context injection
â”‚   â””â”€â”€ audio_playback.py   # Play Gemini audio responses
â”œâ”€â”€ layer3/
â”‚   â”œâ”€â”€ task_executor.py    # Gemini 3 Flash background tasks
â”‚   â””â”€â”€ tools.py            # Function declarations
â””â”€â”€ utils/
    â”œâ”€â”€ buffer.py           # Rolling buffer implementations
    â””â”€â”€ observe.py          # Langfuse observability (optional)
```

---

## Data Flows

### Passive Mode (always running)

```
System Audio â†’ faster-whisper (local) â†’ transcript text â†’ rolling buffer
Screen       â†’ mss + Pillow (local)   â†’ JPEG frames    â†’ rolling buffer
Transcript   â†’ string match "jarvis"  â†’ no match       â†’ continue buffering
```

Zero API calls. Runs indefinitely on local compute.

### Active Mode (wake word triggered)

```
1. "Jarvis" detected in transcript
2. Open Gemini Live API WebSocket session
3. Inject buffered context (transcript + screen frames)
4. Stream live audio + screen at 1fps
5. Receive and play voice responses
6. 30s silence â†’ close session â†’ return to passive
```

### Task Delegation

```
1. User: "Hey Jarvis, research competitor pricing and make a doc"
2. Live API: "On it, I'll let you know when it's ready."
3. Live API emits function_call â†’ start_background_task(...)
4. Gemini 3 Flash runs with code_execution tool
5. Result injected back into Live API session
6. Jarvis speaks: "The competitor analysis is ready. I found..."
```

---

## Cost

| Layer | Cost |
|-------|------|
| Layer 1 â€” Local Whisper + screen capture | **$0** (local compute) |
| Layer 2 â€” Gemini 2.5 Flash Live API | Free tier (Google AI Studio) |
| Layer 3 â€” Gemini 3 Flash API | Free tier (Google AI Studio) |
| **Total for hackathon** | **$0** |

---

## Hackathon Tracks

| Track | How Jarvis Fits |
|-------|----------------|
| ğŸ§  **Marathon Agent** | Maintains continuity across long sessions via rolling context buffer. Background Gemini 3 agent runs autonomously on complex tasks. |
| ğŸ‘¨â€ğŸ« **Real-Time Teacher** | Uses Gemini Live API to synthesize live video + audio for adaptive, contextual assistance. |
| â˜¯ï¸ **Vibe Engineering** | When asked to fix code, the Gemini 3 agent can write, test, and verify code autonomously via code execution. |

---

## License

MIT